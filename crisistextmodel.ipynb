{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61cc00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import Lime, LimeBase\n",
    "from captum._utils.models.linear_model import SkLearnLinearRegression, SkLearnLasso\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9b6ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/6rqzhrhs5fxg5txvp3n0m_t80000gq/T/ipykernel_4671/834969739.py:11: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9bfb10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/Ishita/Workspace/PES/sem6/capstone/Datasets/pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c962a825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_info</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>informative</td>\n",
       "      <td>island barbuda literallyyound water hurrican irma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informative</td>\n",
       "      <td>usa num pm h tag h tagyoupd email h tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>informative</td>\n",
       "      <td>hurrican irma destroy upward num barbuda offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>informative</td>\n",
       "      <td>num pm track andyoupd hurrican irma h tag h ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>informative</td>\n",
       "      <td>num pm advisori hurrican h tag h tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>informative</td>\n",
       "      <td>hurrican irma first impact nassau bahama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>informative</td>\n",
       "      <td>local resourc h tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>informative</td>\n",
       "      <td>whoa ! email pull one last minut inbound fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>not_informative</td>\n",
       "      <td>new stori scienc health forom time cardi b com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>informative</td>\n",
       "      <td>watch two cyclist spot ride hurrican irma back...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            text_info                                               text\n",
       "0         informative  island barbuda literallyyound water hurrican irma\n",
       "1         informative            usa num pm h tag h tagyoupd email h tag\n",
       "2         informative  hurrican irma destroy upward num barbuda offic...\n",
       "3         informative  num pm track andyoupd hurrican irma h tag h ta...\n",
       "4         informative               num pm advisori hurrican h tag h tag\n",
       "...               ...                                                ...\n",
       "3515      informative           hurrican irma first impact nassau bahama\n",
       "3516      informative                                local resourc h tag\n",
       "3517      informative  whoa ! email pull one last minut inbound fligh...\n",
       "3518  not_informative  new stori scienc health forom time cardi b com...\n",
       "3519      informative  watch two cyclist spot ride hurrican irma back...\n",
       "\n",
       "[3520 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7dbdf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def targ(x):\n",
    "#     if x['text_info']=='informative':\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15adf2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label']=df.apply(lambda x:targ(x),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e1adb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90763d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2=df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1023834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv(\"/Users/Ishita/Workspace/PES/sem6/capstone/Datasets/minidataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cbb063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cd8f655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cwd=\"/Users/Ishita/Workspace/PES/sem6/capstone/Datasets\"\n",
    "ls=[]\n",
    "# for filename in os.listdir(cwd):\n",
    "#     df=pd.read_csv(filename)\n",
    "ls.append(df)\n",
    "res=pd.concat(ls)\n",
    "lsval=[]\n",
    "def fun(x):\n",
    "    lsval.append((1 if x['text_info']=='informative' else 0,x['text']))\n",
    "    \n",
    "res.apply(fun,axis=1)\n",
    "len(lsval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be49568",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lsval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "884d67f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lsval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b5dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4226\n",
      "Num of classes: 2\n"
     ]
    }
   ],
   "source": [
    "ag_train,ag_val=lsval[:2816],lsval[2816:]\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "word_counter = Counter()\n",
    "for (label, line) in ag_train:\n",
    "    word_counter.update(tokenizer(line))\n",
    "voc = Vocab(word_counter)\n",
    "\n",
    "print('Vocabulary size:', len(voc))\n",
    "\n",
    "num_class = len(set(label for label, _ in ag_train))\n",
    "print('Num of classes:', num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1563fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n"
     ]
    }
   ],
   "source": [
    "print(len(ag_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81d7bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBagModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs, offsets):\n",
    "        embedded = self.embedding(inputs, offsets)\n",
    "        return self.linear(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05e90ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels = torch.tensor([label  for label, _ in batch]) \n",
    "    text_list = [tokenizer(line) for _, line in batch]\n",
    "    \n",
    "    # flatten tokens across the whole batch\n",
    "    text = torch.tensor([voc[t] for tokens in text_list for t in tokens])\n",
    "    # the offset of each example\n",
    "    offsets = torch.tensor(\n",
    "        [0] + [len(tokens) for tokens in text_list][:-1]\n",
    "    ).cumsum(dim=0)\n",
    "\n",
    "    return labels, text, offsets\n",
    "\n",
    "train_loader = DataLoader(ag_train, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(ag_val, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd8937a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "end of epoch   1 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   2 | valid accuracy    0.794 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   3 | valid accuracy    0.794 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   4 | valid accuracy    0.794 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   5 | valid accuracy    0.795 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   6 | valid accuracy    0.797 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   7 | valid accuracy    0.804 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   8 | valid accuracy    0.804 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   9 | valid accuracy    0.801 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  10 | valid accuracy    0.803 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  11 | valid accuracy    0.801 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  12 | valid accuracy    0.800 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  13 | valid accuracy    0.797 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  14 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  15 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  16 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  17 | valid accuracy    0.794 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  18 | valid accuracy    0.791 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  19 | valid accuracy    0.795 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  20 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "EMB_SIZE = 128\n",
    "CHECKPOINT = './models/embedding_bag.pt'\n",
    "USE_PRETRAINED = False  # change to False if you want to retrain your own model\n",
    "\n",
    "def train_model(train_loader, val_loader):\n",
    "    model = EmbeddingBagModel(len(voc), EMB_SIZE, num_class)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):      \n",
    "        # training\n",
    "        model.train()\n",
    "        total_acc, total_count = 0, 0\n",
    "        \n",
    "        for idx, (label, text, offsets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predited_label = model(text, offsets)\n",
    "            loss(predited_label, label).backward()\n",
    "            optimizer.step()\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print('epoch {:3d} | {:5d}/{:5d} batches | accuracy {:8.3f}'.format(\n",
    "                    epoch, idx + 1, len(train_loader), total_acc / total_count\n",
    "                ))\n",
    "                total_acc, total_count = 0, 0       \n",
    "        \n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        total_acc, total_count = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for label, text, offsets in val_loader:\n",
    "                predited_label = model(text, offsets)\n",
    "                total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "                total_count += label.size(0)\n",
    "\n",
    "        print('-' * 59)\n",
    "        print('end of epoch {:3d} | valid accuracy {:8.3f} '.format(epoch, total_acc / total_count))\n",
    "        print('-' * 59)\n",
    "    \n",
    "    #torch.save(model, CHECKPOINT)\n",
    "    return model\n",
    "        \n",
    "eb_model = torch.load(CHECKPOINT) if USE_PRETRAINED else train_model(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7883c41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "end of epoch   1 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   2 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   3 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   4 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   5 | valid accuracy    0.791 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   6 | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   7 | valid accuracy    0.797 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   8 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch   9 | valid accuracy    0.800 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  10 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  11 | valid accuracy    0.801 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  12 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  13 | valid accuracy    0.794 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  14 | valid accuracy    0.795 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  15 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  16 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  17 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  18 | valid accuracy    0.800 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  19 | valid accuracy    0.794 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "end of epoch  20 | valid accuracy    0.798 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "EMB_SIZE = 128\n",
    "#CHECKPOINT = './models/embedding_bag_ag_news.pt'\n",
    "USE_PRETRAINED = False  # change to False if you want to retrain your own model\n",
    "\n",
    "def train_model(train_loader, val_loader):\n",
    "    model = EmbeddingBagModel(len(voc), EMB_SIZE, num_class)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):      \n",
    "        # training\n",
    "        model.train()\n",
    "        total_acc, total_count = 0, 0\n",
    "        \n",
    "        for idx, (label, text, offsets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predited_label = model(text, offsets)\n",
    "            loss(predited_label, label).backward()\n",
    "            optimizer.step()\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print('epoch {:3d} | {:5d}/{:5d} batches | accuracy {:8.3f}'.format(\n",
    "                    epoch, idx + 1, len(train_loader), total_acc / total_count\n",
    "                ))\n",
    "                total_acc, total_count = 0, 0       \n",
    "        \n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        total_acc, total_count = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for label, text, offsets in val_loader:\n",
    "                predited_label = model(text, offsets)\n",
    "                total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "                total_count += label.size(0)\n",
    "\n",
    "        print('-' * 59)\n",
    "        print('end of epoch {:3d} | valid accuracy {:8.3f} '.format(epoch, total_acc / total_count))\n",
    "        print('-' * 59)\n",
    "    \n",
    "    torch.save(model, \"model\")\n",
    "    return model\n",
    "        \n",
    "eb_model = train_model(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7451fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "# test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "# print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4b8976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probability: 0.9303\n"
     ]
    }
   ],
   "source": [
    "test_label = 1\n",
    "\n",
    "test_line =(\"dispatch respond area hit hard h tag vonda doreen napl assist victim hurrican irma proud ! h tag\")\n",
    "test_labels, test_text, test_offsets = collate_batch([(test_label, test_line)])\n",
    "\n",
    "probs = F.softmax(eb_model(test_text, test_offsets), dim=1).squeeze(0)\n",
    "print('Prediction probability:', round(probs[test_labels[0]].item(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5033458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the batch dimension for the embedding-bag model\n",
    "def forward_func(text, offsets):\n",
    "    return eb_model(text.squeeze(0), offsets)\n",
    "\n",
    "# encode text indices into latent representations & calculate cosine similarity\n",
    "def exp_embedding_cosine_distance(original_inp, perturbed_inp, _, **kwargs):\n",
    "    original_emb = eb_model.embedding(original_inp, None)\n",
    "    perturbed_emb = eb_model.embedding(perturbed_inp, None)\n",
    "    distance = 1 - F.cosine_similarity(original_emb, perturbed_emb, dim=1)\n",
    "    return torch.exp(-1 * (distance ** 2) / 2)\n",
    "\n",
    "# binary vector where each word is selected independently and uniformly at random\n",
    "def bernoulli_perturb(text, **kwargs):\n",
    "    probs = torch.ones_like(text) * 0.5\n",
    "    return torch.bernoulli(probs).long()\n",
    "\n",
    "# remove absenst token based on the intepretable representation sample\n",
    "def interp_to_input(interp_sample, original_input, **kwargs):\n",
    "    return original_input[interp_sample.bool()].view(original_input.size(0), -1)\n",
    "\n",
    "lasso_lime_base = LimeBase(\n",
    "    forward_func, \n",
    "    interpretable_model=SkLearnLasso(alpha=0.08),\n",
    "    similarity_func=exp_embedding_cosine_distance,\n",
    "    perturb_func=bernoulli_perturb,\n",
    "    perturb_interpretable_space=True,\n",
    "    from_interp_rep_transform=interp_to_input,\n",
    "    to_interp_rep_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1631eabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Lime Base attribution:   0%|                          | 0/32000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:   3%|▍             | 910/32000 [00:00<00:17, 1819.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:   6%|▋            | 1820/32000 [00:01<00:20, 1490.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:   8%|█            | 2666/32000 [00:01<00:18, 1572.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  11%|█▍           | 3534/32000 [00:02<00:17, 1632.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  14%|█▊           | 4471/32000 [00:02<00:16, 1715.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  17%|██▏          | 5338/32000 [00:03<00:16, 1664.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  19%|██▌          | 6180/32000 [00:03<00:15, 1669.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  22%|██▉          | 7104/32000 [00:04<00:14, 1724.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:   1%|              | 176/32000 [02:15<6:47:45,  1.30it/s]\u001b[A\u001b[A\n",
      "Lime Base attribution:   7%|█              | 2191/32000 [01:14<16:54, 29.37it/s]\n",
      "\n",
      "\n",
      "Lime Base attribution:  27%|███▌         | 8756/32000 [00:05<00:15, 1470.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  30%|███▉         | 9654/32000 [00:06<00:14, 1559.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  33%|███▉        | 10608/32000 [00:06<00:12, 1658.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  36%|████▎       | 11452/32000 [00:07<00:12, 1636.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  39%|████▌       | 12332/32000 [00:07<00:11, 1671.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  41%|████▉       | 13176/32000 [00:08<00:12, 1558.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  44%|█████▎      | 14040/32000 [00:08<00:11, 1604.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  46%|█████▌      | 14853/32000 [00:09<00:11, 1459.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  49%|█████▊      | 15601/32000 [00:09<00:11, 1432.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  51%|██████      | 16330/32000 [00:10<00:11, 1366.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  54%|██████▍     | 17246/32000 [00:11<00:09, 1492.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  57%|██████▊     | 18123/32000 [00:11<00:08, 1564.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  59%|███████     | 18957/32000 [00:12<00:08, 1593.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  62%|███████▍    | 19893/32000 [00:12<00:07, 1673.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  65%|███████▊    | 20796/32000 [00:13<00:06, 1712.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  68%|████████▏   | 21731/32000 [00:13<00:05, 1758.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  71%|████████▍   | 22640/32000 [00:14<00:05, 1775.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  74%|████████▊   | 23574/32000 [00:14<00:04, 1802.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  76%|█████████▏  | 24478/32000 [00:15<00:04, 1741.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  79%|█████████▌  | 25408/32000 [00:15<00:03, 1775.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  82%|█████████▉  | 26338/32000 [00:16<00:03, 1800.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  85%|██████████▏ | 27292/32000 [00:16<00:02, 1831.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  88%|██████████▌ | 28225/32000 [00:17<00:02, 1841.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  91%|██████████▉ | 29148/32000 [00:17<00:01, 1828.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  94%|███████████▎| 30065/32000 [00:18<00:01, 1829.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution:  97%|███████████▌| 30985/32000 [00:18<00:00, 1832.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Lime Base attribution: 100%|████████████| 32000/32000 [00:19<00:00, 1667.52it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution range: -0.05361732840538025 to 0.20071446895599365\n"
     ]
    }
   ],
   "source": [
    "attrs = lasso_lime_base.attribute(\n",
    "    test_text.unsqueeze(0), # add batch dimension for Captum\n",
    "    target=test_labels,\n",
    "    additional_forward_args=(test_offsets,),\n",
    "    n_samples=32000,\n",
    "    show_progress=True\n",
    ").squeeze(0)\n",
    "\n",
    "print('Attribution range:', attrs.min().item(), 'to', attrs.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3df204a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">dispatch</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">respond</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">area</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">hit</mark> <mark style=\"background-color:rgba(0,255,0,0.33393357543095636)\">hard</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">h</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">tag</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">vonda</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">doreen</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">napl</mark> <mark style=\"background-color:rgba(0,255,0,0.22945198356232807)\">assist</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">victim</mark> <mark style=\"background-color:rgba(0,255,0,0.4480116839503113)\">hurrican</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">irma</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">proud</mark> <mark style=\"background-color:rgba(255,0,0,0.2315541586872934)\">!</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">h</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">tag</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_text_attr(attrs):\n",
    "    rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "    alpha = lambda x: abs(x) ** 0.5\n",
    "    token_marks = [\n",
    "        f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "        for token, attr in zip(tokenizer(test_line), attrs.tolist())\n",
    "    ]\n",
    "    \n",
    "    display(HTML('<p>' + ' '.join(token_marks) + '</p>'))\n",
    "    \n",
    "show_text_attr(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e390cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e32e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
